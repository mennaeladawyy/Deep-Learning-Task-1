# -*- coding: utf-8 -*-
"""Deep Learning Task 1, VGG16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pjjlpQNvOtM0mh6sB0dlF98qRghZQSUb
"""

import numpy as np
import pandas as pd
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import load_img
from keras.utils import to_categorical
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import random
import os

from keras.models import Sequential
from keras import layers
from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation,GlobalMaxPooling2D
from keras import applications
from keras import optimizers
from keras.applications import VGG16
from keras.models import Model

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

image_size = 224
input_shape = (image_size, image_size, 3)
epochs = 5
batch_size = 16
pre_trained_model = VGG16(input_shape=input_shape, include_top=False, weights="imagenet")

for layer in pre_trained_model.layers[:15]:
    layer.trainable = False

for layer in pre_trained_model.layers[15:]:
    layer.trainable = True

last_layer = pre_trained_model.get_layer('block5_pool')
last_output = last_layer.output

x = GlobalMaxPooling2D()(last_output)
x = Dense(512, activation='relu')(x)
x = Dropout(0.5)(x)
x = layers.Dense(1, activation='sigmoid')(x)

model = Model(pre_trained_model.input, x)

from tensorflow.keras import optimizers

model.compile(loss='binary_crossentropy',
              optimizer=optimizers.SGD(learning_rate=1e-4, momentum=0.9),
              metrics=['accuracy'])

model.summary()

from google.colab import drive
drive.mount('/content/drive')

train_path = '/content/drive/My Drive/Dataset/train'
test_path = '/content/drive/My Drive/Dataset/test'
val_path = '/content/drive/My Drive/Dataset/val'

import tensorflow as tf
train_batches= ImageDataGenerator(preprocessing_function= tf.keras.applications.mobilenet.preprocess_input).flow_from_directory( directory=train_path, target_size=(224,224), batch_size= 10)
test_batches= ImageDataGenerator(preprocessing_function= tf.keras.applications.mobilenet.preprocess_input).flow_from_directory( directory=test_path, target_size=(224,224), batch_size= 10, shuffle = False )
val_batches= ImageDataGenerator(preprocessing_function= tf.keras.applications.mobilenet.preprocess_input).flow_from_directory( directory=val_path, target_size=(224,224), batch_size= 10)

imgs,labels= next(train_batches)

image_size = (224, 224)
batch_size = 10

train_datagen = ImageDataGenerator(
    preprocessing_function=tf.keras.applications.mobilenet.preprocess_input,
    rotation_range=15,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest',
    width_shift_range=0.1,
    height_shift_range=0.1
)

test_val_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input)

train_batches = train_datagen.flow_from_directory(
    directory=train_path,
    target_size=image_size,
    batch_size=batch_size,
    class_mode='binary'
)

val_batches = test_val_datagen.flow_from_directory(
    directory=val_path,
    target_size=image_size,
    batch_size=batch_size,
    class_mode='binary',
    shuffle=False
)

test_batches = test_val_datagen.flow_from_directory(
    directory=test_path,
    target_size=image_size,
    batch_size=batch_size,
    class_mode='binary',
    shuffle=False
)

imgs, labels = next(train_batches)

import matplotlib.pyplot as plt
import numpy as np

train_generator = train_batches

train_images, train_labels = next(train_generator)

plt.figure(figsize=(12, 12))
for i in range(9):
    plt.subplot(3, 3, i+1)
    plt.imshow(train_images[i])
    plt.axis('off')

plt.tight_layout()
plt.show()

history = model.fit(
    train_batches,
    epochs=epochs,
    validation_data=val_batches,
    validation_steps=len(val_batches),
    steps_per_epoch=len(train_batches)
)

model.save('/content/drive/MyDrive/model.h5')

from tensorflow.keras.models import load_model
model = load_model('/content/drive/MyDrive/model.h5')

loss, accuracy = model.evaluate(val_batches)
print(f"Test: accuracy = {accuracy:.6f}  ;  loss = {loss:.6f}")

import numpy as np
import matplotlib.pyplot as plt

def plot_model_history(model_history, acc='accuracy', val_acc='val_accuracy'):
    fig, axs = plt.subplots(1, 2, figsize=(15, 5))

    # Accuracy Plot
    axs[0].plot(range(1, len(model_history.history[acc]) + 1), model_history.history[acc])
    axs[0].plot(range(1, len(model_history.history[val_acc]) + 1), model_history.history[val_acc])
    axs[0].set_title('Model Accuracy')
    axs[0].set_ylabel('Accuracy')
    axs[0].set_xlabel('Epoch')
    axs[0].set_xticks(np.arange(1, len(model_history.history[acc]) + 1, max(1, len(model_history.history[acc]) // 10)))
    axs[0].legend(['Train', 'Validation'], loc='best')

    # Loss Plot
    axs[1].plot(range(1, len(model_history.history['loss']) + 1), model_history.history['loss'])
    axs[1].plot(range(1, len(model_history.history['val_loss']) + 1), model_history.history['val_loss'])
    axs[1].set_title('Model Loss')
    axs[1].set_ylabel('Loss')
    axs[1].set_xlabel('Epoch')
    axs[1].set_xticks(np.arange(1, len(model_history.history['loss']) + 1, max(1, len(model_history.history['loss']) // 10)))
    axs[1].legend(['Train', 'Validation'], loc='best')

    plt.show()

plot_model_history(history)

import numpy as np

Y_val = val_batches.classes

y_pred_prob = model.predict(val_batches)

y_pred = (y_pred_prob > 0.5).astype(int).flatten()

print("True Labels:", Y_val[:10])
print("Predicted Labels:", y_pred[:10])

threshold = 0.5

y_final = (y_pred_prob > threshold).astype(int).flatten()

print("Predicted Probabilities:", y_pred_prob[:10].flatten())  # First 10 probabilities
print("Final Binary Predictions:", y_final[:10])  # First 10 binary class labels

y_final.size

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

confusion_mtx = confusion_matrix(Y_val, y_final)

plt.figure(figsize=(8, 8))
sns.heatmap(confusion_mtx, annot=True, fmt="d", cmap="Greens", linewidths=0.5, linecolor="gray")

plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

from sklearn.metrics import classification_report
report = classification_report(Y_val, y_final, target_names=['0','1'])
print(report)

from sklearn.metrics import classification_report
report = classification_report(Y_val, y_final, target_names=['Cat', 'Dog'])
print("Classification Report:\n", report)

import os
import pandas as pd

test_filenames = os.listdir(test_path)

test_df = pd.DataFrame({'filename': test_filenames})

nb_samples = len(test_df)

print(test_df.head())
print(f"Total test samples: {nb_samples}")

from tensorflow.keras.preprocessing.image import ImageDataGenerator

test_gen = ImageDataGenerator(rescale=1.0 / 255)

test_generator = test_gen.flow_from_dataframe(
    dataframe=test_df,
    directory=test_path,
    x_col='filename',
    y_col=None,
    class_mode=None,
    batch_size=batch_size,
    target_size=(image_size, image_size),
    shuffle=False
)

print(f"Test Generator: {len(test_generator)} batches of {batch_size} images")

test_filenames = os.listdir(test_path)
test_filenames = [f for f in test_filenames if f.lower().endswith(('png', 'jpg', 'jpeg'))]
test_df = pd.DataFrame({'filename': test_filenames})

nb_samples = len(test_df)
print(test_df.head())
print(f"Total test samples: {nb_samples}")

test_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input)

test_generator = test_datagen.flow_from_directory(
    directory=test_path,
    target_size=image_size,
    batch_size=batch_size,
    class_mode=None,  # No labels needed for testing
    shuffle=False
)

print(f"Test Generator: {len(test_generator)} batches of {batch_size} images")

predict = model.predict(test_generator, steps=np.ceil(nb_samples / batch_size))